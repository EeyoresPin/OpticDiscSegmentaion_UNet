batch_size: 4
iters: 3000

train_dataset:
  type: Dataset
  dataset_root: optic_disc_seg
  train_path: optic_disc_seg\train_list.txt
  num_classes: 2
  transforms:
    - type: Resize
      target_size: [512, 512]
    - type: Normalize
      mean: [0.5, 0.5, 0.5]
      std: [0.5, 0.5, 0.5]
  mode: train
  separator: ' '

val_dataset:
  type: Dataset
  dataset_root: optic_disc_seg
  val_path: optic_disc_seg\val_list.txt
  num_classes: 2
  transforms:
    - type: Resize
      target_size: [512, 512]
    - type: Normalize
      mean: [0.5, 0.5, 0.5]
      std: [0.5, 0.5, 0.5]
  mode: val
  separator: ' '

optimizer:
  type: Adam
  weight_decay: 0.0
  beta1: 0.9
  beta2: 0.999
  epsilon: 1.0e-8

lr_scheduler: # Related settings for learning rate
  type: PolynomialDecay 
  learning_rate: 0.01
  power: 0.9
  end_lr: 0


model:
  type: UNet
  num_classes: 2
  use_deconv: True



loss:
  types:
    - type: CrossEntropyLoss
  coef: [1]

save_dir: output
log_iters: 10
save_interval: 1000